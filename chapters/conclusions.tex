\chapter{Conclusions}\label{ch:conclusions}

The goal of this dissertation has been to combine physical sensing techniques
with physically motivated machine learning models to produce actionable
environmental insights. A specific focus was placed on water quality and air
quality for which traditional measurements can be challenging to model directly
from physics. In the water quality regime, reflectance spectra captured by
remote sensing platforms are related to the composition of water via the wavelength
dependent absorption and scattering by dissolved chemicals and suspended
particulates. Directly relating these observed spectra to chemical
concentrations would require perfect knowledge of all sources present in order
simulate the radiative transfer of sunlight into the water and back to an
observer. Similarly in the  quality regime, sensors can be used to measure
the distribution of airborne particulates but fully modeling the atmospheric
transport and relevant chemical processes that lead to PM measurements remains
computational infeasible at spatial and temporal scales relevant to human
interactions. Machine learning methods therefore provide an ideal tool to take
advantage of growing data volumes to fill this gap.

% construction of robot team
In Chapter~\ref{ch:robot-team}, we presented and autonomous team of robotic
sentinels designed to coordinate the collection of reflectance spectra with in
situ measurements for a comprehensive suite of water quality parameters. In just
a few minutes, the USV is able to capture thousands of individual
measurements precisely colocated with reflectance spectra captured during UAV
flights. A thorough data processing pipeline was developed to rapidly georectify
captured HSI and convert the result into reflectance data cubes. Timing
results indicate that each raw HSI can be fully processed within 4 seconds using
only the onboard processing computer. Since HSI are captured roughly every 5
seconds, this means that data from the robot team can be processed in near
\textit{real time} as they are captured, making it possible to collect and
analyze HSI during a field deployment.

% development of live network for PM monitoring
Next, in Chapter~\ref{ch:air-network}, we described the air quality monitors
designed for the MINTS air quality network. To date, over 100 of these sensors
have been deployed throughout Texas. After introducing the optical particle
counters utilized in these sensors, we detailed a containerized data backend
designed to process real time measurements from each sensor in the network.
This backend was then connected to an open-source tool called Grafana to create
live dashboards for all incoming sensor data. These dashboards provide immediate
insight into local air quality in the context of the local synoptic scene.

% supervised ML
We then utilized the robot team in Chapter~\ref{ch:robot-team-supervised} to
develop machine learning models which directly map reflectance spectra captured
by the UAV to the in situ measurements made by the USV. Random forests were used
due to the simplicity of their underlying decision tree model \textit{and}
their superior performance on supervised machine learning tasks for tabular
data. With the increased data volume generated by the robot team, we showed
that these models can be augmented using conformal prediction applied to an
additional validation set in order to estimate accurate, distribution-free
confidence intervals for model predictions. Other machine learning approaches
for mapping remote sensing imagery to water quality parameters can be found in
the literature. However, it is exceedingly rare for researchers to evaluate the
uncertainty of trained model predictions independent of model performance on a
hold-out testing set. We therefore see our introduction of Conformal
Prediction in this domain as a significant contribution-- for insights gained
from machine learning methods to be \textit{actionable}, a realistic assessment
of prediction uncertainty is critical.

In addition to estimating confidence intervals, we utilized permutation
importance to identify the most influential wavelengths for each target
variable. Absorption features often present within narrow wavelength
bands, and therefore, ranked feature importance provides a useful tool for
increasing model explainability. For example, the CDOM model favored red
wavelengths which makes sense as high concentrations of CDOM impart water with a
brown color, and red wavelengths can be distinguished independently from
variations in green and yellow light due to vegetation. For every target
variable considered, training the final model using only the top 25 most
important features led to improved model performance.

Each trained model was then applied to collected HSI to rapidly map the spatial
distribution of each parameter across the pond. Interestingly, the models for
CDOM, crude oil, optical brighteners, and each of the measured ions showed a
large spatial gradient between the main body of the pond and an enclosed alcove
on the western side where mixing is restricted by a narrow opening.
The concentrations of chlorophyll a and blue--green algae
peaked near the shore, as expected. The ability for these maps to
distinguish small spatial gradients demonstrates the value of this approach; the
USV can easily miss small pockets of elevated measurement values while the UAV
easily covers the entire area.

% GTM

For situations where specific contaminants are not be known in advance, it still
may be possible to identify their presence solely based on their signatures in
HSI spectra. In Chapter~\ref{ch:robot-team-gtm} we utilized generative
topographic mapping to solve this problem by modeling the distribution of
reflectance spectra using a low-dimensional latent space. The latent space of
the GTM can be visualized in two dimensions where the distance between
points corresponds to the degree of similarity between the original spectra.

We first applied the GTM to water-only pixels from HSI captured across the
same pond that was explored in Chapter~\ref{ch:robot-team-supervised}. By
coloring each HSI pixel according to its final position in the GTM latent space,
the spatial distribution of the captured reflectance spectra can be easily
visualized on a map.

In a second experiment, we applied the GTM to a comprehensive set of HSI which
included dry foliage around the shore as well as a rhodamine dye plume released into the
pond to directly simulate a localized contaminant source. The resulting GTM
naturally segmented ground and vegetation pixels from the rhodamine dye and the
open water. We then demonstrated how the GTM nodes can be projected back into
the original data space to extract endmember spectra corresponding to
algae and rhodamine. Calculating the normalized spectral similarity score
between each pixel and the extracted signatures provides a proxy to assess
abundance distribution of any contaminant across the water. To illustrate this
point, we used the NS3 to track the dispersion of the rhodamine dye plume
between two successive UAV flights.


% GSM

The GTM did a great job of mapping the distribution of HSI spectra but tying the
location of each pixel in the GTM latent space to the abundance of specific
sources is challenging. In Chapter~\ref{ch:robot-team-gsm}, we address this
shortcoming by developing a new latent model called generative simplex mapping
which directly models endmember mixing. Unlike the rectangular grid of the GTM,
the GSM utilizes an $(n-1)$-simplex for its latent space so that latent space
coordinates are immediately interpretable as the relative abundance of $n$-many
unique sources. Furthermore, the mapping from the GSM latent space to
reflectance spectra captures \textit{both} linear and nonlinear mixing effects.

As a first experiment, we compared the GSM against three varieties of
non-negative matrix factorization for a synthetic dataset of linearly mixed
spectra from the USGS spectral database. Across all noise levels, the GSM
outperformed NMF for both endmember extraction and abundance unmixing. A key
advantage of the GSM is that the model enables estimation of spectral
variability via a precision parameter, $\beta$. For this synthetic dataset, the
$\beta$ parameter learned by the GSM directly matched the level of random noise
introduced into the data.  Additionally, the GSM training algorithm correctly
drove all nonlinear mixing contributions to $0$ for this datasets.

To showcase the ability of the GSM to model nonlinear mixing in realistic HSI,
we next applied the GSM to water-only pixels captured by the robot team which
included the rhodamine dye plume from Chapter~\ref{ch:robot-team-gtm}.
By virtue of being a \textit{probabilistic} model, GSM hyperparameters can be
selected using established metrics such as the Bayesian information criterion.
Using the BIC  we found that a 3 component model accurately described the HSI
with the endmembers corresponding to water, vegetation, and rhodamine. We then
applied the trained GSM to map the abundance of each endmember by simply
extracting the coordinates of each pixel in the GSM latent space. Like the GTM,
the GSM is able to accurately track the dispersion of the rhodamine dye plume,
but has the additional advantage that the abundance is truly the inferred
abundance and not just spectral similarity.

% HAVOK

Finally, in Chapter~\ref{ch:havok}, we switched gears and returned to the air
quality network. Here the goal was to develop a physics-based model for the
dynamics of PM that can be applied to provide short-term forecasts and identify
outliers in PM time series corresponding to intermittent pollution events.
Importantly, we noted from observational data that PM time series generally
follow a diurnal cycle. This motivated the use of the Hankel Alternative View of
Koopman method which models chaotic time series by identifying an underlying linear
model and an intermittent external forcing term.

We extended the original HAVOK model to allow for \textit{multiple} external forcing
functions and applied the method to PM 2.5 time series data captured in North
Texas during the summer of 2023. The resulting HAVOK model was stable over long
integration periods, achieving a remarkable RMSE of 0.2167 $\mu g/m^3$ when
integrated across two days of hold-out testing data. By thresholding values of
the learned forcing functions, the trained HAVOK model was also able to
accurately identify three abrupt pollution spikes spread throughout the time
series.

To extend the HAVOK model to enable forecasts, we adjusted the
integration scheme to assume that forcing function values are piece-wise
constant between each sample. This greatly simplified the forecasting problem as
integrating the HAVOK model forward in time then only relies on the present
values of the model state and forcing functions. For single-step forecasts,
this resulted in an RMSE of 0.0589 on the independent testing data. By utilizing
the transformation matrices obtained from fitting the HAVOK model, we then
evaluated the ability of the method for multi-step forecasts by repeating between
integrating the model forward to obtain the next state vector and using the
updated state to evaluate the next values for the forcing function. We found
that with this simple scheme, accurate multi-step predictions can be made for a
forecasting horizon of up to 30 time steps.

Taken together, the approaches developed in this dissertation underscore the
value of utilizing machine learning to complement physical sensing systems
for environmental monitoring. The measurements from many sensing systems like the
reflectance spectra captured by the UAV and particulate matter concentrations
sampled by optical particle counters are often too complicated to be modeled
directly from first principles. However, the large data volumes collected by
theses systems can be leveraged to develop data-driven machine learning models.
Ultimately, this combination of physical sensing and machine learning offers a
promising approach to address complex environmental challenges. Future research
should continue to explore new machine learning models tailored to extract
actionable insights.



