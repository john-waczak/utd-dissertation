[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "",
    "text": "1 Introduction\nThe goal of this thesis is advancing physical sensing in service of society to provide actionable insights. This goal is pursued by applying physics informed approaches together with a suite of sensing and computational technologies, implementing the reusable paradigm of software defined sensors, i.e. physical sensing elements wrapped in a software layer. This software layer can serve a variety of purposes such as calibration and the provision of enhanced or derived data products. It is part of a broader effort in the MINTS-AI laboratory at the University of Texas at Dallas. Where MINTS-AI is an acronym, Multi-Scale Multi-Use Integrated Intelligent Interactive Sensing in Service of Society for Actionable Insights.\nComprehensive environmental sensing is a timely and beneficial endeavor for a variety of reasons. The growing awareness of major environmental issues such as climate change, pollution, and habitat loss necessitates effective environmental monitoring and management. Comprehensive environmental sensing can provide real-time data on air and water quality, weather patterns, and other environmental factors, assisting in the identification and resolution of environmental issues. This assists in the development and implementation of policies and strategies aimed at reducing environmental impact and increasing sustainability. Given that, for instance, air quality can have significant effects on human health, this has particular societal value.\nExposure to air pollution has been linked to a wide range of health effects (Brook et al. 2010; Kelly and Fussell 2011; Xu et al. 2017), including respiratory and cardiovascular diseases, cancer, and adverse birth outcomes. Further, physical sensing provides valuable data and the basis for international assessments such as the Intergovernmental Panel on Climate Change (IPCC), which seeks to assess the science related to climate change and its impacts on natural and human systems (Houghton, Jenkins, and Ephraums 1990; Houghton et al. 1996, 2001; Solomon et al. 2007; Parry et al. 2007; Metz et al. 2007; Stocker et al. 2013; Field et al. 2014; Edenhofer et al. 2014; Masson-Delmotte et al. 2018; Friedlingstein et al. 2020; Huang et al. 2017).\nComprehensive sensing of the environment can improve decision-making. The real-time and accurate data provided by environmental sensors can aid in informed decision-making regarding various aspects such as traffic management, industrial regulation, and crop planning. For instance, data on air quality can be used to inform decisions about reducing pollution levels, while data on weather patterns can help farmers to plan their crops and reduce water usage. Comprehensive sensing of the environment can be instrumental in emergency response. Real-time data on weather patterns, air quality, water levels and resources, and seismic activity can help emergency responders to prepare for and respond to natural disasters such as hurricanes, floods, and earthquakes. The quick and accurate information can enable effective and timely response, potentially saving lives and reducing the impact of the disaster.\nMany advances in technology have enabled the creation of comprehensive sensing systems that can monitor and analyze data from various sensors and devices in real-time. In this thesis we use a range of technologies including autonomous robotic teams (Dunbabin and Marques 2012; Rubenstein, Cornejo, and Nagpal 2014; Chen et al. 2017), hyperspectral imaging (Plaza et al. 2009; Li et al. 2018; Zhu et al. 2017), mesh networks utilizing the Internet of Things (IoT) (Gubbi et al. 2013; Atzori, Iera, and Morabito 2010; Al-Fuqaha et al. 2015), machine learning (ML) (Goodfellow, Bengio, and Courville 2016; LeCun, Bengio, and Hinton 2015; Jordan and Mitchell 2015), edge computing, high-performance computing, wearable sensors and modern high-performance dynamic programming languages such as Julia (Bezanson et al. 2017) designed for numerical and scientific computing. These technologies have facilitated the collection and processing of large amounts of data from multiple sources, resulting in more accurate and comprehensive environmental monitoring.\nOther sections to ponder:"
  },
  {
    "objectID": "index.html#particulate-matter",
    "href": "index.html#particulate-matter",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "1.1 Particulate Matter",
    "text": "1.1 Particulate Matter\n\ndefinitions\nsensing methods\nphysics of…\nair quality\nconsequences of…"
  },
  {
    "objectID": "index.html#optics-of-aqueous-chemicals",
    "href": "index.html#optics-of-aqueous-chemicals",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "1.2 Optics of Aqueous Chemicals",
    "text": "1.2 Optics of Aqueous Chemicals\n\nincident solar radiation\ntransport through the atmosphere\nMotivating relationship: Beer-Lambert Law\n\nwhat happens when we have multiple dissolved species? i.e. justification for use of ML\n\n\nsection in jackson about reflectivity of water\nTypes of spectra we deal with:\n\nreflectance\nradiance\nsolar irradiance\n\nSolar Geometry"
  },
  {
    "objectID": "index.html#chemical-reaction-kinetics-for-the-working-physicist",
    "href": "index.html#chemical-reaction-kinetics-for-the-working-physicist",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "1.3 Chemical Reaction Kinetics for the Working Physicist",
    "text": "1.3 Chemical Reaction Kinetics for the Working Physicist\n\nreaction extent\nGibbs free energy (mountain-valley-hill)\nreaction order\nreaction networks\ngraph theory for reaction networks\nfundamental reactions\nbimolecular, trimolecular\nderivation via kinetic theory\nthe Maxwell-Boltzmann distribution\nPhotolysis"
  },
  {
    "objectID": "index.html#remote-sensing",
    "href": "index.html#remote-sensing",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "1.4 Remote Sensing",
    "text": "1.4 Remote Sensing\n\nHyper spectral images\ntypes of Imagers\nVegetation Indices\nOrthorectification + Georeferencing = Georectification"
  },
  {
    "objectID": "index.html#on-the-calibration-of-measurement-devices",
    "href": "index.html#on-the-calibration-of-measurement-devices",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "1.5 On the calibration of measurement devices…",
    "text": "1.5 On the calibration of measurement devices…\n\ndiscuss standard curve fitting used for most reference instrument calibration\ndiscuss value of ML for doing the same\nstress importance of probabilistic models\nnon-parametric, non-linear…"
  },
  {
    "objectID": "index.html#uncertainty-quantification",
    "href": "index.html#uncertainty-quantification",
    "title": "WiP: Physical Sensing Coupled with Physics Based Machine Learning",
    "section": "1.6 Uncertainty Quantification",
    "text": "1.6 Uncertainty Quantification\n\nstandard methods (linear propagation of uncertainty)\nMeasurments.jl, i.e., why Julia is awesome\nBayesian frameworks, Ensemble sampling, Markov-Chain-Monte-Carlo\nBayesian Regression\nKernelization and Gaussian Processes\nConformal Prediction and Frequentist Statistics\n\n\n\n\n\nAl-Fuqaha, Ala, Mohsen Guizani, Mehdi Mohammadi, Mohammed Aledhari, and Mutlag Ayyash. 2015. “Internet of Things: A Survey on Enabling Technologies, Protocols, and Applications.” IEEE Communications Surveys & Tutorials 17 (4): 2347–76. https://doi.org/10.1109/COMST.2015.2444095.\n\n\nAtzori, Luigi, Antonio Iera, and Giacomo Morabito. 2010. “The Internet of Things: A Survey.” Computer Networks 54 (15): 2787–2805. https://doi.org/10.1016/j.comnet.2010.05.010.\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B. Shah. 2017. “Julia: A Fresh Approach to Numerical Computing.” SIAM Review 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nBrook, Robert D., Sanjay Rajagopalan, C. Arden Pope III, Jeffrey R. Brook, Aruni Bhatnagar, Ana V. Diez-Roux, Fernando Holguin, et al. 2010. “Particulate Matter Air Pollution and Cardiovascular Disease.” Circulation 121 (21): 2331–78. https://doi.org/10.1161/CIRCULATIONAHA.109.893472.\n\n\nChen, Yan, Xun Zhu, Haibo Wang, Wei Ren, and Simon X. Yang. 2017. “Autonomous Robots with Decentralized, Collective Decision-Making.” Proceedings of the IEEE 105 (2): 321–37. https://doi.org/10.1109/JPROC.2016.2628400.\n\n\nDunbabin, Matthew, and Lino Marques. 2012. “Robotic Mapping of Environmental Variables for Prediction and Control.” Philosophical Transactions of the Royal Society A 370 (1962): 298–308. https://doi.org/10.1098/rsta.2011.0243.\n\n\nEdenhofer, O., R. Pichs-Madruga, Y. Sokona, E. Farahani, S. Kadner, K. Seyboth, A. Adler, et al. 2014. Climate Change 2014: Mitigation of Climate Change. IPCC Working Group II. Cambridge University Press. https://doi.org/10.1017/CBO9781107415416.\n\n\nField, C. B., V. R. Barros, D. J. Dokken, K. J. Mach, M. D. Mastrandrea, T. E. Bilir, M. Chatterjee, et al. 2014. Climate Change 2014: Impacts, Adaptation, and Vulnerability. Part a: Global and Sectoral Aspects. Cambridge University Press. https://doi.org/10.1017/CBO9781107415379.\n\n\nFriedlingstein, Pierre, Matthew W. Jones, Michael O’Sullivan, Robbie M. Andrew, Judith Hauck, Glen P. Peters, Wouter Peters, et al. 2020. “Global Carbon Budget 2020.” Earth System Science Data 12 (4): 3269–3340. https://doi.org/10.5194/essd-12-3269-2020.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. “Deep Learning.” MIT Press. https://doi.org/10.1016/j.neunet.2016.10.003.\n\n\nGubbi, Jayavardhana, Rajkumar Buyya, Slaven Marusic, and Marimuthu Palaniswami. 2013. “Internet of Things (IoT): A Vision, Architectural Elements, and Future Directions.” Future Generation Computer Systems 29 (7): 1645–60. https://doi.org/10.1016/j.future.2013.01.010.\n\n\nHoughton, J. T., Y. Ding, D. J. Griggs, M. Noguer, P. J. van der Linden, X. Dai, K. Maskell, and C. A. Johnson. 2001. Climate Change 2001: The Scientific Basis. Cambridge University Press. https://doi.org/10.1017/CBO9780511546013.\n\n\nHoughton, J. T., G. J. Jenkins, and J. J. Ephraums. 1990. Climate Change: The IPCC Scientific Assessment. Cambridge University Press. https://doi.org/10.1017/CBO9780511623521.\n\n\nHoughton, J. T., L. G. Meira Filho, B. A. Callander, N. Harris, A. Kattenberg, and K. Maskell. 1996. Climate Change 1995: The Science of Climate Change. Cambridge University Press. https://doi.org/10.1017/CBO9780511809286.\n\n\nHuang, Jiaxing, Lejiang Yu, Jianping Guo, Xiaofeng Guo, Wei Wang, Chunyan Liu, and Duoying Ji. 2017. “Assessment of Global Surface Energy Budget Datasets Using Flux Tower Observations.” Journal of Geophysical Research: Atmospheres 122 (14): 7452–75. https://doi.org/10.1002/2016JD026049.\n\n\nJordan, Michael I., and Tom M. Mitchell. 2015. “Machine Learning: Trends, Perspectives, and Prospects.” Science 349 (6245): 255–60. https://doi.org/10.1126/science.aaa8415.\n\n\nKelly, Frank J., and Julian C. Fussell. 2011. “Air Pollution and Public Health: Emerging Hazards and Improved Understanding of Risk.” Environmental Geochemistry and Health 33 (4): 363–73. https://doi.org/10.1007/s10653-011-9415-1.\n\n\nLeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep Learning.” Nature 521 (7553): 436–44. https://doi.org/10.1038/nature14539.\n\n\nLi, Jun, Antonio Plaza, José Bioucas-Dias, Paul Gader, and Jocelyn Chanussot. 2018. “Guest Editorial Deep Learning for Hyperspectral Image Analysis.” IEEE Transactions on Geoscience and Remote Sensing 56 (3): 1362–64. https://doi.org/10.1109/TGRS.2018.2801300.\n\n\nMasson-Delmotte, V., P. Zhai, H.-O. Pörtner, D. Roberts, J. Skea, P. R. Shukla, A. Pirani, et al. 2018. Global Warming of 1.5°c. An IPCC Special Report on the Impacts of Global Warming of 1.5°c Above Pre-Industrial Levels and Related Global Greenhouse Gas Emission Pathways, in the Context of Strengthening the Global Response to the Threat of Climate Change, Sustainable Development, and Efforts to Eradicate Poverty. IPCC Special Report. Intergovernmental Panel on Climate Change. https://www.ipcc.ch/sr15/.\n\n\nMetz, B., O. R. Davidson, P. R. Bosch, R. Dave, and L. A. Meyer. 2007. Climate Change 2007: Mitigation of Climate Change. Cambridge University Press. https://doi.org/10.1017/CBO9780511813573.\n\n\nParry, M. L., O. F. Canziani, J. P. Palutikof, P. J. van der Linden, and C. E. Hanson. 2007. Climate Change 2007: Impacts, Adaptation and Vulnerability. Cambridge University Press. https://doi.org/10.1017/CBO9780511546013.\n\n\nPlaza, Antonio, Jon A. Benediktsson, James W. Boardman, Jason Brazile, Lorenzo Bruzzone, Gustau Camps-Valls, Jocelyn Chanussot, et al. 2009. “Recent Advances in Techniques for Hyperspectral Image Processing.” Remote Sensing of Environment 113 (S1): S110–22. https://doi.org/10.1016/j.rse.2008.10.008.\n\n\nRubenstein, Michael, Alejandro Cornejo, and Radhika Nagpal. 2014. “Programmable Self-Assembly in a Thousand-Robot Swarm.” Science 345 (6198): 795–99. https://doi.org/10.1126/science.1254295.\n\n\nSolomon, S., D. Qin, M. Manning, Z. Chen, M. Marquis, K. B. Averyt, M. Tignor, and H. L. Miller Jr. 2007. Climate Change 2007: The Physical Science Basis. Cambridge University Press. https://doi.org/10.1017/CBO9780511546013.\n\n\nStocker, T. F., D. Qin, G.-K. Plattner, M. Tignor, S. K. Allen, J. Boschung, A. Nauels, Y. Xia, V. Bex, and P. M. Midgley. 2013. Climate Change 2013: The Physical Science Basis. Cambridge University Press. https://doi.org/10.1017/CBO9781107415324.\n\n\nXu, Xiaohui, Feng Deng, Xiuwei Guo, Ping Lv, Hua Zhong, Yuantao Hao, Guocheng Hu, et al. 2017. “Association Between Particulate Matter Air Pollution and Hospital Admissions in Patients with Chronic Obstructive Pulmonary Disease in Beijing, China.” Science of the Total Environment 579: 1616–21. https://doi.org/10.1016/j.scitotenv.2016.11.166.\n\n\nZhu, Xiao Xiang, Devis Tuia, Lichao Mou, Gui-Song Xia, Liangpei Zhang, and Feng Xu. 2017. “Deep Learning in Remote Sensing: A Comprehensive Review and List of Resources.” IEEE Geoscience and Remote Sensing Magazine 5 (4): 8–36. https://doi.org/10.1109/MGRS.2017.2762307."
  },
  {
    "objectID": "GlobalChange.html#the-role-of-sensing",
    "href": "GlobalChange.html#the-role-of-sensing",
    "title": "2  Global Change",
    "section": "2.1 The Role of Sensing",
    "text": "2.1 The Role of Sensing\nSensing technologies can play a critical role in both adaptation and mitigation efforts by providing data and information that can inform decision-making and improve the effectiveness of strategies (United Nations Environment Programme 2017; National Research Council 2010; Centre for Ecology and Hydrology 2017).\nIn adaptation efforts, sensing technologies can provide real-time data on environmental conditions such as temperature, precipitation, sea level, air quality, as well as on the status and health of ecosystems and wildlife. This information can be used to inform early warning systems for natural disasters, to track the spread of vector-borne diseases, and to monitor the impacts of climate change on biodiversity and ecosystem services. Sensing technologies can also provide data on the effectiveness of adaptation measures, such as the performance of sea walls and other infrastructure.\nIn mitigation efforts, sensing technologies can provide data on greenhouse gas emissions and other drivers of global change, as well as on the effectiveness of mitigation measures such as renewable energy and carbon capture and storage. Sensing technologies can also be used to monitor and manage land use changes such as deforestation and urbanization, and to track the impacts of these changes on ecosystems and carbon storage.\nOverall, sensing technologies can provide critical data and information for both adaptation and mitigation efforts, helping to improve decision-making and increase the effectiveness of strategies. The integration of sensing technologies with other tools such as modeling and data analysis can also help to identify new strategies and solutions for addressing global change. There are various sensing technologies and approaches used for monitoring the global environment. Here are some of the key ones:\n\nRemote Sensing: This technology involves using satellites and other airborne platforms to collect data on the Earth’s atmosphere, land, and oceans. Remote sensing provides information on environmental parameters such as temperature, humidity, air quality, land use and land cover, and ocean temperature, salinity, and sea level (Thenkabail 2019; Buyantuyev and Wu 2017; Gamon et al. 2016; Wang et al. 2017; Pasher et al. 2019). Some examples of remote sensing include:\n\nLidar: This technology uses laser pulses to measure distance and can be used to create detailed three-dimensional maps of the environment. Lidar is commonly used to measure forest canopy height, but can also be used to measure atmospheric conditions such as cloud cover and aerosol concentrations.\nImaging Spectroscopy: This technology uses a combination of imaging and spectroscopy to measure the reflectance of different wavelengths of light. Imaging spectroscopy can be used to identify and map different types of vegetation and minerals, and can provide information on the health of plant communities.\nUnmanned Aerial Vehicles (UAVs): These are remote-controlled or autonomous aircraft that can be equipped with sensors for remote and in-situ environmental monitoring. UAVs can be used for mapping and monitoring of large areas, and can collect high-resolution data on environmental conditions.\n\nIn-Situ Sensors: These sensors are used to collect data directly from the environment at the location of interest. They can measure environmental parameters such as temperature, pressure, and humidity, as well as water quality and soil moisture. In situ sensors are commonly used in marine environments to measure ocean temperature, salinity, and other properties. Some examples of in-situ sensing include:\n\nWeather Stations: These are automated weather monitoring systems that collect data on atmospheric conditions such as temperature, humidity, barometric pressure, wind speed and direction, and precipitation. Weather stations can be installed on land or in the ocean to provide continuous monitoring of environmental conditions.\nGround-Based Sensors: These sensors are used to monitor the quality of air, water, and soil. They can detect and measure pollutants such as carbon dioxide, nitrogen dioxide, ozone, sulfur dioxide, and particulate matter. Ground-based sensors are installed in various locations such as cities, industrial sites, and rural areas to provide localized environmental monitoring.\nAcoustic Sensors: These sensors are used to monitor environmental noise levels, including noise from traffic, industrial sources, and natural sources such as wind and waves. Acoustic sensors can provide information on noise levels over time and across different locations.\n\n\nOverall, these sensing technologies play a critical role in monitoring the global environment and can provide valuable information for environmental research, management, and policy-making."
  },
  {
    "objectID": "GlobalChange.html#the-role-of-computational-modelling",
    "href": "GlobalChange.html#the-role-of-computational-modelling",
    "title": "2  Global Change",
    "section": "2.2 The Role of Computational Modelling",
    "text": "2.2 The Role of Computational Modelling\nComputer modeling can play a valuable role in both understanding and predicting global change (Chen et al. 2019; Hantson et al. 2016; DeLucia et al. 2021; Oleson et al. 2013; Clark et al. 2016). For example:\n\nClimate Modeling: Computer models can be used to simulate the Earth’s climate system and predict future climate conditions. These models can incorporate data on greenhouse gas emissions, land use changes, and other factors to project how the Earth’s climate will change over time.\nEcosystem Modeling: Computer models can be used to simulate how ecosystems will respond to changes in environmental conditions, such as changes in temperature, precipitation, and atmospheric composition. These models can help predict how changes in ecosystems will impact biodiversity, ecosystem services, and human well-being.\nCarbon Cycle Modeling: Computer models can be used to simulate the global carbon cycle, which is the exchange of carbon between the Earth’s atmosphere, land, and oceans. These models can help predict how changes in carbon emissions and land use will impact atmospheric carbon dioxide concentrations and global climate.\nAir Quality Modeling: Computer models can be used to simulate air quality, including the dispersion of pollutants in the atmosphere. These models can help predict how changes in emissions and atmospheric conditions will impact air quality and human health.\nHydrological Modeling: Computer models can be used to simulate the movement of water through the Earth’s hydrological cycle. These models can help predict how changes in precipitation, land use, and other factors will impact water availability, quality, and distribution.\n\nOverall, computer modeling can provide valuable insights into the complex processes and interactions that drive global change. These insights can inform policy decisions and help guide efforts to mitigate and adapt to the impacts of global change.\n\n\n\n\nBuyantuyev, Alexander, and Jiquan Wu. 2017. “Remote Sensing Applications for Land Cover and Land-Use Transformations in Semiarid and Arid Environments.” Journal of Arid Environments 140: 1–5. https://doi.org/10.1016/j.jaridenv.2017.01.008.\n\n\nCentre for Ecology and Hydrology. 2017. “Ecological Sensing: A Revolution in Biodiversity Monitoring.” https://www.ceh.ac.uk/news-and-media/blogs/ecological-sensing-revolution-biodiversity-monitoring.\n\n\nChen, Jiawei, Xiaoming Shi, Xinyi Li, Mingjie Wang, Wei Shen, and Yanzhao Liu. 2019. “A Review of Air Quality Modeling: From Gas-Phase to Particulate Matter.” Advances in Atmospheric Sciences 36 (10): 921–47. https://doi.org/10.1007/s00376-019-9047-1.\n\n\nClark, Martyn P., W. Neil Adger, Suraje Dessai, Marisa Goulden, David W. Cash, and Richard and Dickson Stern Nicholas and Gonzalez. 2016. “Urbanization, Climate Change and Economic Growth: Challenges and Opportunities for Policy Makers.” Science of the Total Environment 557-558: 279–91. https://doi.org/10.1016/j.scitotenv.2016.03.022.\n\n\nCostello, Anthony, Mustafa Abbas, Adriana Allen, Sarah Ball, Sarah Bell, Richard Bellamy, Sharon Friel, et al. 2009. “Managing the Health Effects of Climate Change: Lancet and University College London Institute for Global Health Commission.” The Lancet 373 (9676): 1693–733. https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(09)60935-1/fulltext.\n\n\nDeLucia, Evan H., Nuria Gomez-Casanovas, Stephen P. Long, Melanie A. Mayes, Rebecca A. Montgomery, William J. Parton, William J. Sacks, Joshua P. Schimel, Joseph Verfaillie, and Whendee L. Silver. 2021. “The Missing Soil n: Detecting Processes Driving Soil Nitrogen Storage in Complex Ecosystems.” Journal of Ecology 109 (2): 447–59. https://doi.org/10.1111/1365-2745.13550.\n\n\nEdenhofer, O., R. Pichs-Madruga, Y. Sokona, E. Farahani, S. Kadner, K. Seyboth, A. Adler, et al. 2014. Climate Change 2014: Mitigation of Climate Change. IPCC Working Group II. Cambridge University Press. https://doi.org/10.1017/CBO9781107415416.\n\n\nGamon, John A., K. Fred Huemmrich, Robert S. Stone, and Craig E. Tweedie. 2016. “Spatial and Temporal Variation in Primary Productivity (NDVI) of Coastal Alaskan Tundra: Decreased Vegetation Growth Following Earlier Snowmelt.” Remote Sensing of Environment 175: 233–42. https://doi.org/10.1016/j.rse.2015.12.051.\n\n\nHaines, Andrew, R Sari Kovats, Diarmid Campbell-Lendrum, and Carlos Corvalán. 2006. “Climate Change and Human Health: Impacts, Vulnerability and Public Health.” Public Health 120 (7): 585–96. https://doi.org/10.1016/j.puhe.2006.01.002.\n\n\nHantson, Stijn, Almut Arneth, Sandy P. Harrison, Douglas I. Kelley, I. Colin Prentice, Sam S. Rabin, Sally Archibald, et al. 2016. “The Status and Challenge of Global Fire Modelling.” Biogeosciences 13 (11): 3359–75. https://doi.org/10.5194/bg-13-3359-2016.\n\n\nMasson-Delmotte, V., P. Zhai, H.-O. Pörtner, D. Roberts, J. Skea, P. R. Shukla, A. Pirani, et al. 2018. Global Warming of 1.5°c. An IPCC Special Report on the Impacts of Global Warming of 1.5°c Above Pre-Industrial Levels and Related Global Greenhouse Gas Emission Pathways, in the Context of Strengthening the Global Response to the Threat of Climate Change, Sustainable Development, and Efforts to Eradicate Poverty. IPCC Special Report. Intergovernmental Panel on Climate Change. https://www.ipcc.ch/sr15/.\n\n\nNational Research Council. 2010. “Verifying Greenhouse Gas Emissions: Methods to Support International Climate Agreements.” https://www.nap.edu/catalog/12883/verifying-greenhouse-gas-emissions-methods-to-support-international-climate-agreements.\n\n\nOleson, K. W., D. M. Lawrence, G. B. Bonan, and M. G. Flanner. 2013. “Interactions Between Land Use Change and Carbon Cycle Feedbacks.” Global Biogeochemical Cycles 27 (4): 972–83. https://doi.org/10.1002/gbc.20073.\n\n\nPasher, Jon, Bum-Jun Park, Jérôme Théau, Francois Pimont, and Scott Goetz. 2019. “Remote Sensing of Wetlands: An Overview and Practical Guide.” Wetlands Ecology and Management 27 (2): 129–47. https://doi.org/10.1007/s11273-018-9624-3.\n\n\nThenkabail, Prasad S. 2019. “Remote Sensing of Global Croplands for Food Security.” Remote Sensing 11 (10): 1261. https://doi.org/10.3390/rs11101261.\n\n\nUnited Nations. 2015. “Transforming Our World: The 2030 Agenda for Sustainable Development.” UN General Assembly. https://sdgs.un.org/2030agenda.\n\n\nUnited Nations Environment Programme. 2017. “Adaptation Gap Report 2017.” https://www.unep.org/resources/adaptation-gap-report-2017.\n\n\nWang, Donglian, Donghui Xie, Yichun Xie, and Chen Chen. 2017. “Remote Sensing Applications for Urban Water Resources: A Review.” Remote Sensing 9 (8): 829. https://doi.org/10.3390/rs9080829.\n\n\nWorld Health Organization. 2018. “Climate Change and Health.” https://www.who.int/news-room/fact-sheets/detail/climate-change-and-health."
  },
  {
    "objectID": "KeyTechnologies.html#an-introduction-to-some-key-tools-used-in-this-thesis",
    "href": "KeyTechnologies.html#an-introduction-to-some-key-tools-used-in-this-thesis",
    "title": "3  Key Technologies",
    "section": "3.1 An Introduction to Some Key Tools Used in This Thesis",
    "text": "3.1 An Introduction to Some Key Tools Used in This Thesis\n\n3.1.1 Julia for Scientific Computing\nJulia is designed to combine the ease of use and high-level abstractions of languages like Python with the performance of compiled languages like C++, achieving a unique combination of speed and productivity for numerical and scientific computing. Julia is a high-level, high-performance programming language designed for numerical and scientific computing. It combines the ease of use and readability of Python with the speed and efficiency of Fortran or C. Julia has a wide array of scientific computing functionality, making it a powerful language for numerical analysis, data science, and engineering. It has built-in support for arrays and linear algebra, as well as packages for differential equations, optimization, probabilistic programming, data analysis and visualization, parallel and distributed computing, and machine learning. Julia’s combination of performance, expressiveness, and flexibility make it an excellent choice for scientific and engineering applications, allowing for high-level abstractions and rapid prototyping, while still providing low-level control and efficient execution.\nHere are some examples of what can be done easily in Julia that may not be as easy or efficient in other widely used scientific computing languages such as Python or Fortran:\n\nMultiple dispatch: Julia has a powerful multiple dispatch system that allows for generic programming and efficient function overloading. This allows for more flexible and expressive code compared to traditional object-oriented programming (OOP) in Python. Multiple dispatch allows a function to behave differently based on the types and/or number of arguments passed to it. In other words, the behavior of a function can be dispatched’ based on the specific types and/or number of arguments passed to it.\nJust-in-time (JIT) compilation: Julia’s JIT compiler translates high-level Julia code into optimized machine code, making Julia programs run nearly as fast as C or Fortran. In contrast, Python code is interpreted, and Fortran requires pre-compilation.\nDistributed computing: Julia has built-in support for distributed computing, making it easy to parallelize and scale up computations across multiple processors or machines. This is not as easy to do in Python or Fortran.\nUnits and Error Propagation: The Units package in Julia provides a powerful and flexible framework for handling physical units in computations, useful for error propagation and dimensional analysis, helping to ensure that the results are accurate, consistent, easy to interpret, and dimensionally consistent.\nBuilt-in unit testing: Julia has a built-in testing framework that makes it easy to write and run unit tests for your code, ensuring that it works correctly.\nISO characters: Julia supports the use of Greek and other ISO characters in variable and function names, which can make code more readable and expressive, especially in mathematical or scientific contexts.\nInteractive data visualization: Julia has a number of powerful data visualization packages, such as Plots.jl and Makie.jl, that allow for interactive, high-performance data visualization.\nPackage management: Julia has a sophisticated package manager that makes it easy to install, manage, and use third-party packages in your code. This is not as easy to do in Fortran, and while Python has a package manager, Julia’s package manager is faster and more reliable.\nInline C/Fortran/Python/R/Matlab code: Julia allows for inline C, Fortran, Python, R or Matlab code, making it easy to use existing libraries and code written in these languages without having to rewrite everything in Julia.\n\n\n\n3.1.2 Scientific and Physics-based Machine Learning\nScientific machine learning (SciML) refers to the application of Machine Learning (ML) techniques to scientific problems, where the goal is not only to make predictions but also to gain insights into the underlying physical processes (Raissi, Perdikaris, and Karniadakis 2019; Rackauckas et al. 2020; Carleo et al. 2019). SciML involves the integration of domain-specific knowledge and physical models with data-driven techniques, and it has the potential to revolutionize many areas of science and engineering. In this thesis we explore the use of Physics-based machine learning (PBML) (Raissi and Karniadakis 2021; Wu and Zhang 2021) for a variety of applications.\nRecent examples include a paper by (Raissi, Perdikaris, and Karniadakis 2019) that introduces a physics-informed neural network (PINN) framework for solving nonlinear partial differential equations, a paper by (Rackauckas et al. 2020) that proposes a universal differential equation (UDE) approach to scientific machine learning, and a review article by (Carleo et al. 2019) that discusses the use of machine learning in various fields of physics, including condensed matter physics, high-energy physics, and quantum physics. PBML has several advantages over purely data-driven approaches, including:\n\nImproved generalization: PBML models incorporate prior knowledge of the underlying physics, resulting in models that are more interpretable and generalizable. This enables the models to make accurate predictions even with limited training data.\nIncorporation of physical constraints: PBML models can be designed to incorporate physical constraints, such as conservation laws, which can help to ensure physically consistent predictions.\nImproved interpretability: PBML models are more interpretable than purely data-driven models since they are designed to incorporate physical principles. This can enable scientists and engineers to gain deeper insights into the underlying mechanisms of the systems they are studying.\nReduced data requirements: PBML models require less training data than purely data-driven models since they leverage the physics-based priors, reducing the need for large datasets to train accurate models.\nBetter extrapolation: PBML models are better equipped to extrapolate beyond the training data since they incorporate knowledge of the underlying physics, enabling them to make more accurate predictions in new and unseen scenarios.\n\nOverall, PBML has several advantages over purely data-driven approaches, including improved generalization, reduced data requirements, better extrapolation, incorporation of physical constraints, and improved interpretability, making it a valuable tool for scientific and engineering applications.\n\n\n\n\nCarleo, Giuseppe, Kenny Choo, Johannes Hofmann, Edward Huang, Chris Hughes, Michael Hush, Raban Iten, et al. 2019. “Machine Learning and the Physical Sciences.” Reviews of Modern Physics 91 (4): 045002.\n\n\nRackauckas, Christopher, David Kelly, Qing Nie, Jesse Li, Cody Warner, Malvika Dhairya, Jie Fang, et al. 2020. “Universal Differential Equations for Scientific Machine Learning.” arXiv Preprint arXiv:2012.09345.\n\n\nRaissi, Maziar, and George Em Karniadakis. 2021. “Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations.” Journal of Computational Physics 378: 686–707.\n\n\nRaissi, Maziar, Paris Perdikaris, and George Em Karniadakis. 2019. “Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations.” Journal of Computational Physics 378: 686–707.\n\n\nWu, Jingtao, and Xiaohua Zhang. 2021. “A Review on Physics-Informed Machine Learning: Basic Principles, Recent Developments and Future Directions.” Physics Reports 903: 1–45."
  },
  {
    "objectID": "ML.html#overview-of-types-of-ml",
    "href": "ML.html#overview-of-types-of-ml",
    "title": "4  Machine Learning, Physics-Informed Machine Learning, Scientific Machine Learning",
    "section": "4.1 overview of types of ML",
    "text": "4.1 overview of types of ML"
  },
  {
    "objectID": "ML.html#explain-nn-i.e.-neural-network-as-a-function-universal-approximator",
    "href": "ML.html#explain-nn-i.e.-neural-network-as-a-function-universal-approximator",
    "title": "4  Machine Learning, Physics-Informed Machine Learning, Scientific Machine Learning",
    "section": "4.2 explain NN (i.e. neural network as a function + universal approximator)",
    "text": "4.2 explain NN (i.e. neural network as a function + universal approximator)"
  },
  {
    "objectID": "ML.html#explain-physics-informed-nns",
    "href": "ML.html#explain-physics-informed-nns",
    "title": "4  Machine Learning, Physics-Informed Machine Learning, Scientific Machine Learning",
    "section": "4.3 explain Physics Informed NN(s)",
    "text": "4.3 explain Physics Informed NN(s)"
  },
  {
    "objectID": "ML.html#explain-sciml-ude-framework",
    "href": "ML.html#explain-sciml-ude-framework",
    "title": "4  Machine Learning, Physics-Informed Machine Learning, Scientific Machine Learning",
    "section": "4.4 explain SciML + UDE framework",
    "text": "4.4 explain SciML + UDE framework"
  },
  {
    "objectID": "ML.html#use-rlc-circuit-instead-of-spring-mass-to-introduce-the-concept",
    "href": "ML.html#use-rlc-circuit-instead-of-spring-mass-to-introduce-the-concept",
    "title": "4  Machine Learning, Physics-Informed Machine Learning, Scientific Machine Learning",
    "section": "4.5 use RLC circuit instead of Spring mass to introduce the concept",
    "text": "4.5 use RLC circuit instead of Spring mass to introduce the concept"
  },
  {
    "objectID": "ML.html#methods-ive-developed",
    "href": "ML.html#methods-ive-developed",
    "title": "4  Machine Learning, Physics-Informed Machine Learning, Scientific Machine Learning",
    "section": "4.6 methods I’ve developed",
    "text": "4.6 methods I’ve developed\n\nEnsembling and Super Learners\nSelf Organizing Maps\nGenerative Topographic Mapping"
  },
  {
    "objectID": "RobotTeam.html",
    "href": "RobotTeam.html",
    "title": "5  Robot Team",
    "section": "",
    "text": "6 RobotTeam Papers"
  },
  {
    "objectID": "RobotTeam.html#georectification",
    "href": "RobotTeam.html#georectification",
    "title": "5  Robot Team",
    "section": "5.1 georectification",
    "text": "5.1 georectification"
  },
  {
    "objectID": "RobotTeam.html#supervised-ml-for-concentration",
    "href": "RobotTeam.html#supervised-ml-for-concentration",
    "title": "5  Robot Team",
    "section": "5.2 supervised ML for concentration",
    "text": "5.2 supervised ML for concentration"
  },
  {
    "objectID": "RobotTeam.html#super-resolution-if-we-have-time-and-open-data-cube",
    "href": "RobotTeam.html#super-resolution-if-we-have-time-and-open-data-cube",
    "title": "5  Robot Team",
    "section": "5.3 super resolution if we have time (and open data cube)",
    "text": "5.3 super resolution if we have time (and open data cube)"
  },
  {
    "objectID": "RobotTeam.html#solar-geometry",
    "href": "RobotTeam.html#solar-geometry",
    "title": "5  Robot Team",
    "section": "5.4 solar geometry",
    "text": "5.4 solar geometry"
  },
  {
    "objectID": "RobotTeam.html#reflectanceradiance",
    "href": "RobotTeam.html#reflectanceradiance",
    "title": "5  Robot Team",
    "section": "5.5 reflectance/radiance",
    "text": "5.5 reflectance/radiance"
  },
  {
    "objectID": "RobotTeam.html#unsupervised-methods",
    "href": "RobotTeam.html#unsupervised-methods",
    "title": "5  Robot Team",
    "section": "5.6 unsupervised methods",
    "text": "5.6 unsupervised methods"
  },
  {
    "objectID": "RobotTeam.html#synthetic-data-generation",
    "href": "RobotTeam.html#synthetic-data-generation",
    "title": "5  Robot Team",
    "section": "5.7 synthetic data generation",
    "text": "5.7 synthetic data generation"
  },
  {
    "objectID": "RobotTeam.html#robot-team-ii-electric-boogaloo-title-w.i.p.",
    "href": "RobotTeam.html#robot-team-ii-electric-boogaloo-title-w.i.p.",
    "title": "5  Robot Team",
    "section": "6.1 Robot Team II: Electric Boogaloo (title w.i.p.)",
    "text": "6.1 Robot Team II: Electric Boogaloo (title w.i.p.)\n\nDiscuss real time georectification, generation of reflectance data, etc…\nCombine Multiple days of observations\nDiscuss need for both viewing geometry and solar geometry\n\nmake reference to highly nonuniform reflectance as a function of incident angle\nmake reference to Beer’s law as justification for direct determination of concentration of concentration from spectra\nin depth discussion of fluorometers (maybe save this for the dissertation)"
  },
  {
    "objectID": "RobotTeam.html#unsupervised-classification-of-hyperspectral-imagery-for-rapid-characterization-of-novel-environments-with-autonomous-robotic-teams",
    "href": "RobotTeam.html#unsupervised-classification-of-hyperspectral-imagery-for-rapid-characterization-of-novel-environments-with-autonomous-robotic-teams",
    "title": "5  Robot Team",
    "section": "6.2 Unsupervised Classification of Hyperspectral Imagery for Rapid Characterization of Novel Environments with Autonomous Robotic Teams",
    "text": "6.2 Unsupervised Classification of Hyperspectral Imagery for Rapid Characterization of Novel Environments with Autonomous Robotic Teams\n\n6.2.1 K-means / Fuzzy K-means\n\n\n6.2.2 Self Organizing Maps\n\nfit an SOM model to the data\nfor each pixel in entire map, assign best matching unit (use distinguishable colors for a \\(10\\times 10\\) or \\(25\\times 25\\) SOM grid)\nFor class, investigate the learned “spectrum” representation and compare against known chemical spectra.\n\nis there a database we could try to use to look up possible species in the reflectance spectra? ### Generative Topographic Mapping ### analysis ideas\n\nThe nice feature of both the SOM and the GTM is we can reinterpret them to be spectral-unmixing models. Each SOM node has a feature vector of identical length to the input vector. Similarly, the mean projection \\(y(x;W)\\) in GTM represents the center of a gaussian in data space. Thus, we can reinterpret these feature vectors and gaussian centers as representative endmember spectra for the dataset. Further, the topographic properties of these methods ensure we have similarity between classes (at least in the latent space). For the GTM we are guarenteed that the data space projections of our GTM nodes will be similar. We should see if this holds for SOM. We can also interpret the cluster means from K-means as our endmembers.\nFor SOM and GTM once we have fit the models, we can look at the map of “winning nodes” (BMU for SOM and Mean for GTM) and perform a secondary clustering (via K-means or DBSCAN). These new clusters can define our endmember-bundles for a spectral-unmixing model.\nOnce we have these maps, we should color the point by which day the data came from to see if there are any interesting groups or if the data are distributd across observation days\nWe should make sure we apply the method for unsupervised classification to the dye-released images (see if the maps mirror the diffusion of dye). Pick a day where we have &gt;1 dye flight. Make a map for both cases to illustrate how rapidly fitting an unsupervised model on the fly can enable near real time tracking of plume evolution (good for defense, oil spills, etc…). –&gt; can we then construct a vector field / flow field from the difference and predict the plume evolution? Maybe this would be a good excuse to try lagrangian particle tracking…\nProvided our GTM/SOM fits, we should try a secondary\nFrom nodes/node clusters, can we identify spectral endmembers that represent chemicals we measure (e.g. chlorophyll)?\nFrom node activations (SOM) or responsabilities (GTM) can we fit a good model that competes with predictions from full spectra? (dimensionality reduction demonstration)\ncluster viewing geometry separate from refelctances and use resulting viewing geo classes to color GTM/SOM map of reflectance data"
  },
  {
    "objectID": "RobotTeam.html#spectral-indices-for-rapid-hsi-surveys-unsupervised-and-supervised-methods-via-sciml",
    "href": "RobotTeam.html#spectral-indices-for-rapid-hsi-surveys-unsupervised-and-supervised-methods-via-sciml",
    "title": "5  Robot Team",
    "section": "6.3 Spectral Indices for Rapid HSI Surveys: Unsupervised and Supervised Methods via SciML",
    "text": "6.3 Spectral Indices for Rapid HSI Surveys: Unsupervised and Supervised Methods via SciML\n\nApply to PROSPECT database as a simple test case\nApply to our own Data\n\nMutliple Endmember Spectral Mixture Analysis\ngeneralize Spectral Unmixing Models unmixing models… with gaussian process we could think of an infinite basis of gaussians describing “peaks” in the spectrum”. Can we try to kernelize this procedure?"
  },
  {
    "objectID": "RobotTeam.html#synthetic-data-generation-for-hyperspectral-imaging-with-autonomous-robotic-teams",
    "href": "RobotTeam.html#synthetic-data-generation-for-hyperspectral-imaging-with-autonomous-robotic-teams",
    "title": "5  Robot Team",
    "section": "6.4 Synthetic Data Generation for Hyperspectral Imaging with Autonomous Robotic Teams",
    "text": "6.4 Synthetic Data Generation for Hyperspectral Imaging with Autonomous Robotic Teams\n\nVariational Autoencoders\nGroup transformations, e.g. rotations, reflections, translations, cropping, etc… (do these make sense if boat data is point observation)\nAdvanced sampling methods for regions with"
  },
  {
    "objectID": "RobotTeam.html#uncertainty-quantification-via-partial-p.",
    "href": "RobotTeam.html#uncertainty-quantification-via-partial-p.",
    "title": "5  Robot Team",
    "section": "6.5 Uncertainty Quantification via \\(\\partial P\\).",
    "text": "6.5 Uncertainty Quantification via \\(\\partial P\\).\n\nCategorize Methods into two categories:\n\nquantifying uncertainty in collected data\nquantifying model uncertainty\n\nConformal Prediction (we have a NN code for doing this in flux. Just need to apply it)\nRepresentativeness Uncertainty i.e. when georectifying HSI images and reducing spatial extend via ilat and ilon settings, also compute the stdev for each grainy pixel\nMeasurements.jl forward mode once we have the representativeness uncertainty.\nNeed a way to quantify uncertainty from Boat sensors…\nSensativity Analysis with w/ automatic differentiation"
  },
  {
    "objectID": "SensorNetwork.html",
    "href": "SensorNetwork.html",
    "title": "6  Sensor Network",
    "section": "",
    "text": "7 Sensor Network + SciML"
  },
  {
    "objectID": "SensorNetwork.html#docker-nodered-influxdb-grafana",
    "href": "SensorNetwork.html#docker-nodered-influxdb-grafana",
    "title": "6  Sensor Network",
    "section": "6.1 Docker, NodeRed, InfluxDB, Grafana",
    "text": "6.1 Docker, NodeRed, InfluxDB, Grafana"
  },
  {
    "objectID": "SensorNetwork.html#hamiltonian-nn-stuff",
    "href": "SensorNetwork.html#hamiltonian-nn-stuff",
    "title": "6  Sensor Network",
    "section": "6.2 Hamiltonian NN stuff",
    "text": "6.2 Hamiltonian NN stuff"
  },
  {
    "objectID": "SensorNetwork.html#neural-ode",
    "href": "SensorNetwork.html#neural-ode",
    "title": "6  Sensor Network",
    "section": "6.3 neural ode",
    "text": "6.3 neural ode"
  },
  {
    "objectID": "SensorNetwork.html#tda",
    "href": "SensorNetwork.html#tda",
    "title": "6  Sensor Network",
    "section": "6.4 TDA",
    "text": "6.4 TDA"
  },
  {
    "objectID": "SensorNetwork.html#evaluation-of-local-chaos-in-sharedairdfwnetwork",
    "href": "SensorNetwork.html#evaluation-of-local-chaos-in-sharedairdfwnetwork",
    "title": "6  Sensor Network",
    "section": "7.1 Evaluation of local chaos in SharedAirDFWNetwork",
    "text": "7.1 Evaluation of local chaos in SharedAirDFWNetwork\n\nThis gives me an excuse to work with the sensor data\nTrain GTM, SOM, and Variational Autoencoder to produce lower dimensional representation of all data from a central node, e.g. in \\(\\mathbb{R}^2\\).\n\nFor VAE, test a range of dimensions from the number of sensors down to 2 (better for visualization)\n\nAnalyze the variety of methods from DataDrivenDiffEq.jl to infer dynamics in the low dimensional space\nCan we infer some kind of Hamiltonian from the data and do a HamiltonianNN approach?\n\nStart of with a standard kinetic-energy style Hamiltonian e.g. \\(\\sum_i \\frac{1}{2} \\dot{x}_i^2\\) where \\(x_i\\) is the\nuse DataDrivenDiffEq approach to learn the associated potential energy term\nalternatively, attempt to capture diurnal cycle (or other relevant time scales) by learning coordinate representation that forces dynamics to be uncoupled harmonic oscillators a la Hamilton-Jacobi theory.\nTest if this hamiltonian NN model can then be transfered to another central node with an appropriate shift in the “total energy”\n\nAttempt to analyze the 2d data to infer Koopman operator. We should treat the original sensor values as observables on which the learned koopman operator acts. This should be doable if the NN is just a function.\nuse DMD appraoch to identify a “forcing” coordinate that can identify when we switch nodes as in Chaos as an intermittently forced linear system\nvideo on Physics Informed DMD\nDeep Learning to Discover Coordinates for Dynamics: Autoencoders & Physics Informed Machine Learning\nNOTE: we may need to impute missing values. We shoud do so with either my GPR code or with other ML methods + ConformalPrediction. Provided uncertainty estimates, we should then think about how to propagate errors through our analysis via Measurements.jl, IntervalArithmetic,"
  },
  {
    "objectID": "MasterChemicalMechanism.html",
    "href": "MasterChemicalMechanism.html",
    "title": "7  Master Chemical Mechanism",
    "section": "",
    "text": "8 Chemical Data Assimilation & ActivePure Work"
  },
  {
    "objectID": "MasterChemicalMechanism.html#sensor-fusion",
    "href": "MasterChemicalMechanism.html#sensor-fusion",
    "title": "7  Master Chemical Mechanism",
    "section": "7.1 sensor fusion",
    "text": "7.1 sensor fusion"
  },
  {
    "objectID": "MasterChemicalMechanism.html#photolysis",
    "href": "MasterChemicalMechanism.html#photolysis",
    "title": "7  Master Chemical Mechanism",
    "section": "7.2 photolysis",
    "text": "7.2 photolysis"
  },
  {
    "objectID": "MasterChemicalMechanism.html#docker-ingestion-framework",
    "href": "MasterChemicalMechanism.html#docker-ingestion-framework",
    "title": "7  Master Chemical Mechanism",
    "section": "7.3 docker ingestion framework",
    "text": "7.3 docker ingestion framework"
  },
  {
    "objectID": "MasterChemicalMechanism.html#master-chemical-mechanism",
    "href": "MasterChemicalMechanism.html#master-chemical-mechanism",
    "title": "7  Master Chemical Mechanism",
    "section": "7.4 master chemical mechanism",
    "text": "7.4 master chemical mechanism"
  },
  {
    "objectID": "MasterChemicalMechanism.html#data-assimilation",
    "href": "MasterChemicalMechanism.html#data-assimilation",
    "title": "7  Master Chemical Mechanism",
    "section": "7.5 data assimilation",
    "text": "7.5 data assimilation"
  },
  {
    "objectID": "MasterChemicalMechanism.html#activepure-research-lab",
    "href": "MasterChemicalMechanism.html#activepure-research-lab",
    "title": "7  Master Chemical Mechanism",
    "section": "8.1 ActivePure Research Lab",
    "text": "8.1 ActivePure Research Lab\n\nOverview of all sensor in sensor matrix\nOverview of measurement capabilities (list of species, uncertainty levels, etc…)\nOverview of containerized data acquisition pipeline\n\nNodeRed\nInfluxDB\nGrafana\nQuarto\nAutomatic Alerts\nAutomatic Reports"
  },
  {
    "objectID": "MasterChemicalMechanism.html#kinetics-and-chemical-data-assimilation",
    "href": "MasterChemicalMechanism.html#kinetics-and-chemical-data-assimilation",
    "title": "7  Master Chemical Mechanism",
    "section": "8.2 Kinetics and Chemical Data Assimilation",
    "text": "8.2 Kinetics and Chemical Data Assimilation\n\nMCM Implementation in Julia\nDirect computation of Photolysis rates\nCombination with Dr. Lary’s AutoChem\nAddition of Ion Chemistry from MIT Lightning disseration\nVisualization of chemical cycles\nSciML methods to infer below detection limits"
  },
  {
    "objectID": "SuperResolution.html#cloud-shadow-mask-for-sentinel-2",
    "href": "SuperResolution.html#cloud-shadow-mask-for-sentinel-2",
    "title": "8  Super Resolution",
    "section": "8.1 Cloud & Shadow Mask for Sentinel-2",
    "text": "8.1 Cloud & Shadow Mask for Sentinel-2\n\n8.1.1 ML Type\n\nSupervised Classification ### ML Methods\nSingle Pixel w/ Tree Based Methods\nDeep NN with Convolutional Layers ### Features\nSentinel 2 Multi-band Imagery\nLand Type\nViewing Geometry\nSolar Geometry ### Targets\nSentinel 2 Cloud Mask + Cloud Shadow Mask"
  },
  {
    "objectID": "SuperResolution.html#cloud-shadow-fill",
    "href": "SuperResolution.html#cloud-shadow-fill",
    "title": "8  Super Resolution",
    "section": "8.2 Cloud & Shadow Fill",
    "text": "8.2 Cloud & Shadow Fill\n\n8.2.1 ML Type\n\nsupervised regression ### ML Methods\npixel based (Would it make sense to do something else here?) ### Features\nSentinel 2 Multi-band Imagery\nSentinel 2 Cloud Mask & Cloud Shadow Mask\nSentinel 1 SAR Variables (GRD or SLC or both?)\n10 m Digital Elevation Map\nViewing Geometry\nSolar Geometry\nLand Type ### Targets\nCloudless & Shadowless Sentinel 2 Multi-band imagery"
  },
  {
    "objectID": "SuperResolution.html#sentinel-2-rgb-spatial-super-resolution",
    "href": "SuperResolution.html#sentinel-2-rgb-spatial-super-resolution",
    "title": "8  Super Resolution",
    "section": "8.3 Sentinel 2 RGB Spatial Super Resolution",
    "text": "8.3 Sentinel 2 RGB Spatial Super Resolution\n\n8.3.1 ML Type\n\nSupervised Regression ### ML Methods\nThis has to be a Deep NN method using convolution to get the upsampling. I don’t think we can do this with pixel based models (using tree methods)\nProbably should use a GAN ### Features\nHigh (spatial) Resolution NAIP RGB Image\nSentinel 2 Multi-band Imagery\nSentinel 1 SAR Variables (GRD or SLC or both?)\n10 m Digital Elevation Map\nViewing Geometry\nSolar Geometry\nLand Type ### Targets\nSentinel RGB Bands @ NAIP Resolution ### Loss Function Terms ### Notes We could make a model that uses all 3 bands (RGB) simultaneously, or we can make a model for a single band that we validate against R, G, and B bands individually. This has the added perc of increasing the training samples. This will be much easier to then apply to all bands of the sentinel imagery (and perhaps Sentinel 1, etc…) independently. We could try:\nRed, Green, Blue bands separately\nBlack and White converted RGB image\nData Augmentation via Scaling / Rotation / Reflection"
  },
  {
    "objectID": "SuperResolution.html#sentinel-2-multiband-spatial-super-resolution",
    "href": "SuperResolution.html#sentinel-2-multiband-spatial-super-resolution",
    "title": "8  Super Resolution",
    "section": "8.4 Sentinel 2 Multiband Spatial Super Resolution",
    "text": "8.4 Sentinel 2 Multiband Spatial Super Resolution\n\n8.4.1 ML Type\n\nSupervised Regression ### ML Methods\nThis has to be a Deep NN method using convolution to get the upsampling. I don’t think we can do this with pixel based models (using tree methods)\nProbably should use a GAN ### Features\nHigh (spatial) Resolution NAIP RGB Image\nSentinel 2 Multi-band Imagery\nSentinel 1 SAR Variables (GRD or SLC or both?)\n10 m Digital Elevation Map\nViewing Geometry\nSolar Geometry\nLand Type ### Targets\nSentinel RGB Bands @ NAIP Resolution ### Loss Function Terms"
  },
  {
    "objectID": "SuperResolution.html#sentinel-2-multiband-spectral-super-resolution",
    "href": "SuperResolution.html#sentinel-2-multiband-spectral-super-resolution",
    "title": "8  Super Resolution",
    "section": "8.5 Sentinel 2 Multiband Spectral Super Resolution",
    "text": "8.5 Sentinel 2 Multiband Spectral Super Resolution\n\n8.5.1 ML Type\n\nSupervised Regression ### ML Methods\nThis can be pixel based ### Features\nSentinel 2 Multi-band Imagery\nSentinel 1 SAR Variables (GRD or SLC or both?)\n10 m Digital Elevation Map\nViewing Geometry\nSolar Geometry\nUAV Hyperspectral Image ### Targets\nSentinel Hyperspectral Imagery (i.e. Sentinel at all HSI Bands) ### Loss Function Terms"
  },
  {
    "objectID": "TechnicalNotes.html#real-time-georectification-of-drone-based-imagery",
    "href": "TechnicalNotes.html#real-time-georectification-of-drone-based-imagery",
    "title": "9  Technical Notes",
    "section": "9.1 Real Time Georectification of Drone Based Imagery",
    "text": "9.1 Real Time Georectification of Drone Based Imagery\n\nGeorectification of pushbroom HSI\nGeorectifcation of square visible + thermal FLIR imagery ## Self Organizing Maps ## Bayesian Optimization with Gaussian Process Regression ## Gaussian Process Regression / Classification in MLJ ## Solar Geometry? (probably not necessary)"
  },
  {
    "objectID": "OtherTopics.html",
    "href": "OtherTopics.html",
    "title": "10  Other Topics",
    "section": "",
    "text": "Sparse Nonlinear Models for Fluid Dynamics with Machine Learning and Optimization\nResidual Dynamic Mode Decomposition: A very easy way to get error bounds for your DMD computations\nDeep Learning of Dynamics and Coordinates with SINDy Autoencoders\nIdentifying Dominant Balance Physics from Data"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Al-Fuqaha, Ala, Mohsen Guizani, Mehdi Mohammadi, Mohammed Aledhari, and\nMutlag Ayyash. 2015. “Internet of Things: A Survey on Enabling\nTechnologies, Protocols, and Applications.” IEEE\nCommunications Surveys & Tutorials 17 (4): 2347–76. https://doi.org/10.1109/COMST.2015.2444095.\n\n\nAtzori, Luigi, Antonio Iera, and Giacomo Morabito. 2010. “The\nInternet of Things: A Survey.” Computer Networks 54\n(15): 2787–2805. https://doi.org/10.1016/j.comnet.2010.05.010.\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B. Shah. 2017.\n“Julia: A Fresh Approach to Numerical Computing.” SIAM\nReview 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nBrook, Robert D., Sanjay Rajagopalan, C. Arden Pope III, Jeffrey R.\nBrook, Aruni Bhatnagar, Ana V. Diez-Roux, Fernando Holguin, et al. 2010.\n“Particulate Matter Air Pollution and Cardiovascular\nDisease.” Circulation 121 (21): 2331–78. https://doi.org/10.1161/CIRCULATIONAHA.109.893472.\n\n\nBuyantuyev, Alexander, and Jiquan Wu. 2017. “Remote Sensing\nApplications for Land Cover and Land-Use Transformations in Semiarid and\nArid Environments.” Journal of Arid Environments 140:\n1–5. https://doi.org/10.1016/j.jaridenv.2017.01.008.\n\n\nCarleo, Giuseppe, Kenny Choo, Johannes Hofmann, Edward Huang, Chris\nHughes, Michael Hush, Raban Iten, et al. 2019. “Machine Learning\nand the Physical Sciences.” Reviews of Modern Physics 91\n(4): 045002.\n\n\nCentre for Ecology and Hydrology. 2017. “Ecological Sensing: A\nRevolution in Biodiversity Monitoring.” https://www.ceh.ac.uk/news-and-media/blogs/ecological-sensing-revolution-biodiversity-monitoring.\n\n\nChen, Jiawei, Xiaoming Shi, Xinyi Li, Mingjie Wang, Wei Shen, and\nYanzhao Liu. 2019. “A Review of Air Quality Modeling: From\nGas-Phase to Particulate Matter.” Advances in Atmospheric\nSciences 36 (10): 921–47. https://doi.org/10.1007/s00376-019-9047-1.\n\n\nChen, Yan, Xun Zhu, Haibo Wang, Wei Ren, and Simon X. Yang. 2017.\n“Autonomous Robots with Decentralized, Collective\nDecision-Making.” Proceedings of the IEEE 105 (2):\n321–37. https://doi.org/10.1109/JPROC.2016.2628400.\n\n\nClark, Martyn P., W. Neil Adger, Suraje Dessai, Marisa Goulden, David W.\nCash, and Richard and Dickson Stern Nicholas and Gonzalez. 2016.\n“Urbanization, Climate Change and Economic Growth: Challenges and\nOpportunities for Policy Makers.” Science of the Total\nEnvironment 557-558: 279–91. https://doi.org/10.1016/j.scitotenv.2016.03.022.\n\n\nCostello, Anthony, Mustafa Abbas, Adriana Allen, Sarah Ball, Sarah Bell,\nRichard Bellamy, Sharon Friel, et al. 2009. “Managing the Health\nEffects of Climate Change: Lancet and University College London\nInstitute for Global Health Commission.” The Lancet 373\n(9676): 1693–733. https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(09)60935-1/fulltext.\n\n\nDeLucia, Evan H., Nuria Gomez-Casanovas, Stephen P. Long, Melanie A.\nMayes, Rebecca A. Montgomery, William J. Parton, William J. Sacks,\nJoshua P. Schimel, Joseph Verfaillie, and Whendee L. Silver. 2021.\n“The Missing Soil n: Detecting Processes Driving Soil Nitrogen\nStorage in Complex Ecosystems.” Journal of Ecology 109\n(2): 447–59. https://doi.org/10.1111/1365-2745.13550.\n\n\nDunbabin, Matthew, and Lino Marques. 2012. “Robotic Mapping of\nEnvironmental Variables for Prediction and Control.”\nPhilosophical Transactions of the Royal Society A 370 (1962):\n298–308. https://doi.org/10.1098/rsta.2011.0243.\n\n\nEdenhofer, O., R. Pichs-Madruga, Y. Sokona, E. Farahani, S. Kadner, K.\nSeyboth, A. Adler, et al. 2014. Climate Change 2014: Mitigation of\nClimate Change. IPCC Working Group II. Cambridge\nUniversity Press. https://doi.org/10.1017/CBO9781107415416.\n\n\nField, C. B., V. R. Barros, D. J. Dokken, K. J. Mach, M. D. Mastrandrea,\nT. E. Bilir, M. Chatterjee, et al. 2014. Climate Change 2014:\nImpacts, Adaptation, and Vulnerability. Part a: Global and Sectoral\nAspects. Cambridge University Press. https://doi.org/10.1017/CBO9781107415379.\n\n\nFriedlingstein, Pierre, Matthew W. Jones, Michael O’Sullivan, Robbie M.\nAndrew, Judith Hauck, Glen P. Peters, Wouter Peters, et al. 2020.\n“Global Carbon Budget 2020.” Earth System Science\nData 12 (4): 3269–3340. https://doi.org/10.5194/essd-12-3269-2020.\n\n\nGamon, John A., K. Fred Huemmrich, Robert S. Stone, and Craig E.\nTweedie. 2016. “Spatial and Temporal Variation in Primary\nProductivity (NDVI) of Coastal Alaskan Tundra: Decreased Vegetation\nGrowth Following Earlier Snowmelt.” Remote Sensing of\nEnvironment 175: 233–42. https://doi.org/10.1016/j.rse.2015.12.051.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. “Deep\nLearning.” MIT Press. https://doi.org/10.1016/j.neunet.2016.10.003.\n\n\nGubbi, Jayavardhana, Rajkumar Buyya, Slaven Marusic, and Marimuthu\nPalaniswami. 2013. “Internet of Things (IoT): A\nVision, Architectural Elements, and Future Directions.”\nFuture Generation Computer Systems 29 (7): 1645–60. https://doi.org/10.1016/j.future.2013.01.010.\n\n\nHaines, Andrew, R Sari Kovats, Diarmid Campbell-Lendrum, and Carlos\nCorvalán. 2006. “Climate Change and Human Health: Impacts,\nVulnerability and Public Health.” Public Health 120 (7):\n585–96. https://doi.org/10.1016/j.puhe.2006.01.002.\n\n\nHantson, Stijn, Almut Arneth, Sandy P. Harrison, Douglas I. Kelley, I.\nColin Prentice, Sam S. Rabin, Sally Archibald, et al. 2016. “The\nStatus and Challenge of Global Fire Modelling.”\nBiogeosciences 13 (11): 3359–75. https://doi.org/10.5194/bg-13-3359-2016.\n\n\nHoughton, J. T., Y. Ding, D. J. Griggs, M. Noguer, P. J. van der Linden,\nX. Dai, K. Maskell, and C. A. Johnson. 2001. Climate Change 2001:\nThe Scientific Basis. Cambridge University Press. https://doi.org/10.1017/CBO9780511546013.\n\n\nHoughton, J. T., G. J. Jenkins, and J. J. Ephraums. 1990. Climate\nChange: The IPCC Scientific Assessment. Cambridge University Press.\nhttps://doi.org/10.1017/CBO9780511623521.\n\n\nHoughton, J. T., L. G. Meira Filho, B. A. Callander, N. Harris, A.\nKattenberg, and K. Maskell. 1996. Climate Change 1995: The Science\nof Climate Change. Cambridge University Press. https://doi.org/10.1017/CBO9780511809286.\n\n\nHuang, Jiaxing, Lejiang Yu, Jianping Guo, Xiaofeng Guo, Wei Wang,\nChunyan Liu, and Duoying Ji. 2017. “Assessment of Global Surface\nEnergy Budget Datasets Using Flux Tower Observations.”\nJournal of Geophysical Research: Atmospheres 122 (14): 7452–75.\nhttps://doi.org/10.1002/2016JD026049.\n\n\nJordan, Michael I., and Tom M. Mitchell. 2015. “Machine Learning:\nTrends, Perspectives, and Prospects.” Science 349\n(6245): 255–60. https://doi.org/10.1126/science.aaa8415.\n\n\nKelly, Frank J., and Julian C. Fussell. 2011. “Air Pollution and\nPublic Health: Emerging Hazards and Improved Understanding of\nRisk.” Environmental Geochemistry and Health 33 (4):\n363–73. https://doi.org/10.1007/s10653-011-9415-1.\n\n\nLeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep\nLearning.” Nature 521 (7553): 436–44. https://doi.org/10.1038/nature14539.\n\n\nLi, Jun, Antonio Plaza, José Bioucas-Dias, Paul Gader, and Jocelyn\nChanussot. 2018. “Guest Editorial Deep Learning for Hyperspectral\nImage Analysis.” IEEE Transactions on Geoscience and Remote\nSensing 56 (3): 1362–64. https://doi.org/10.1109/TGRS.2018.2801300.\n\n\nMasson-Delmotte, V., P. Zhai, H.-O. Pörtner, D. Roberts, J. Skea, P. R.\nShukla, A. Pirani, et al. 2018. Global Warming of 1.5°c. An IPCC\nSpecial Report on the Impacts of Global Warming of 1.5°c Above\nPre-Industrial Levels and Related Global Greenhouse Gas Emission\nPathways, in the Context of Strengthening the Global Response to the\nThreat of Climate Change, Sustainable Development, and Efforts to\nEradicate Poverty. IPCC Special Report. Intergovernmental\nPanel on Climate Change. https://www.ipcc.ch/sr15/.\n\n\nMetz, B., O. R. Davidson, P. R. Bosch, R. Dave, and L. A. Meyer. 2007.\nClimate Change 2007: Mitigation of Climate Change. Cambridge\nUniversity Press. https://doi.org/10.1017/CBO9780511813573.\n\n\nNational Research Council. 2010. “Verifying Greenhouse Gas\nEmissions: Methods to Support International Climate Agreements.”\nhttps://www.nap.edu/catalog/12883/verifying-greenhouse-gas-emissions-methods-to-support-international-climate-agreements.\n\n\nOleson, K. W., D. M. Lawrence, G. B. Bonan, and M. G. Flanner. 2013.\n“Interactions Between Land Use Change and Carbon Cycle\nFeedbacks.” Global Biogeochemical Cycles 27 (4): 972–83.\nhttps://doi.org/10.1002/gbc.20073.\n\n\nParry, M. L., O. F. Canziani, J. P. Palutikof, P. J. van der Linden, and\nC. E. Hanson. 2007. Climate Change 2007: Impacts, Adaptation and\nVulnerability. Cambridge University Press. https://doi.org/10.1017/CBO9780511546013.\n\n\nPasher, Jon, Bum-Jun Park, Jérôme Théau, Francois Pimont, and Scott\nGoetz. 2019. “Remote Sensing of Wetlands: An Overview and\nPractical Guide.” Wetlands Ecology and Management 27\n(2): 129–47. https://doi.org/10.1007/s11273-018-9624-3.\n\n\nPlaza, Antonio, Jon A. Benediktsson, James W. Boardman, Jason Brazile,\nLorenzo Bruzzone, Gustau Camps-Valls, Jocelyn Chanussot, et al. 2009.\n“Recent Advances in Techniques for Hyperspectral Image\nProcessing.” Remote Sensing of Environment 113 (S1):\nS110–22. https://doi.org/10.1016/j.rse.2008.10.008.\n\n\nRackauckas, Christopher, David Kelly, Qing Nie, Jesse Li, Cody Warner,\nMalvika Dhairya, Jie Fang, et al. 2020. “Universal Differential\nEquations for Scientific Machine Learning.” arXiv Preprint\narXiv:2012.09345.\n\n\nRaissi, Maziar, and George Em Karniadakis. 2021. “Physics-Informed\nNeural Networks: A Deep Learning Framework for Solving Forward and\nInverse Problems Involving Nonlinear Partial Differential\nEquations.” Journal of Computational Physics 378:\n686–707.\n\n\nRaissi, Maziar, Paris Perdikaris, and George Em Karniadakis. 2019.\n“Physics-Informed Neural Networks: A Deep Learning Framework for\nSolving Forward and Inverse Problems Involving Nonlinear Partial\nDifferential Equations.” Journal of Computational\nPhysics 378: 686–707.\n\n\nRubenstein, Michael, Alejandro Cornejo, and Radhika Nagpal. 2014.\n“Programmable Self-Assembly in a Thousand-Robot Swarm.”\nScience 345 (6198): 795–99. https://doi.org/10.1126/science.1254295.\n\n\nSolomon, S., D. Qin, M. Manning, Z. Chen, M. Marquis, K. B. Averyt, M.\nTignor, and H. L. Miller Jr. 2007. Climate Change 2007: The Physical\nScience Basis. Cambridge University Press. https://doi.org/10.1017/CBO9780511546013.\n\n\nStocker, T. F., D. Qin, G.-K. Plattner, M. Tignor, S. K. Allen, J.\nBoschung, A. Nauels, Y. Xia, V. Bex, and P. M. Midgley. 2013.\nClimate Change 2013: The Physical Science Basis. Cambridge\nUniversity Press. https://doi.org/10.1017/CBO9781107415324.\n\n\nThenkabail, Prasad S. 2019. “Remote Sensing of Global Croplands\nfor Food Security.” Remote Sensing 11 (10): 1261. https://doi.org/10.3390/rs11101261.\n\n\nUnited Nations. 2015. “Transforming Our World: The 2030 Agenda for\nSustainable Development.” UN General Assembly. https://sdgs.un.org/2030agenda.\n\n\nUnited Nations Environment Programme. 2017. “Adaptation Gap Report\n2017.” https://www.unep.org/resources/adaptation-gap-report-2017.\n\n\nWang, Donglian, Donghui Xie, Yichun Xie, and Chen Chen. 2017.\n“Remote Sensing Applications for Urban Water Resources: A\nReview.” Remote Sensing 9 (8): 829. https://doi.org/10.3390/rs9080829.\n\n\nWorld Health Organization. 2018. “Climate Change and\nHealth.” https://www.who.int/news-room/fact-sheets/detail/climate-change-and-health.\n\n\nWu, Jingtao, and Xiaohua Zhang. 2021. “A Review on\nPhysics-Informed Machine Learning: Basic Principles, Recent Developments\nand Future Directions.” Physics Reports 903: 1–45.\n\n\nXu, Xiaohui, Feng Deng, Xiuwei Guo, Ping Lv, Hua Zhong, Yuantao Hao,\nGuocheng Hu, et al. 2017. “Association Between Particulate Matter\nAir Pollution and Hospital Admissions in Patients with Chronic\nObstructive Pulmonary Disease in Beijing, China.” Science of\nthe Total Environment 579: 1616–21. https://doi.org/10.1016/j.scitotenv.2016.11.166.\n\n\nZhu, Xiao Xiang, Devis Tuia, Lichao Mou, Gui-Song Xia, Liangpei Zhang,\nand Feng Xu. 2017. “Deep Learning in Remote Sensing: A\nComprehensive Review and List of Resources.” IEEE Geoscience\nand Remote Sensing Magazine 5 (4): 8–36. https://doi.org/10.1109/MGRS.2017.2762307."
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix A — Additional stuff",
    "section": "",
    "text": "You might put some computer output here, or maybe additional tables. It is possible to have multiple appendices. Just list them in the appropriate place within _quarto.yml."
  }
]